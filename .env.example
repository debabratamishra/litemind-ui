# LLM WebUI Configuration

# API URLs
OLLAMA_API_URL=http://localhost:11434
VLLM_API_URL=http://localhost:8001
FASTAPI_URL=http://localhost:8000

# Database
CHROMA_DB_PATH=/app/chroma_db
SQLALCHEMY_DATABASE_URI=sqlite+aiosqlite:///app/llm_webui.db

# File paths
UPLOAD_FOLDER=/app/uploads
STORAGE_PATH=/app/storage

# Security
SECRET_KEY=your-secret-key-change-this-in-production

# Performance tuning
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
NUMEXPR_NUM_THREADS=4

# vLLM Configuration (Optional)
# HF_TOKEN=your-huggingface-token-here

# Cache directories (automatically configured by docker-compose)
# HUGGINGFACE_CACHE_DIR=${HOME}/.cache/huggingface
# OLLAMA_CACHE_DIR=${HOME}/.ollama

# Development settings
DEBUG=0
RELOAD=0

# Logging
LOG_LEVEL=INFO